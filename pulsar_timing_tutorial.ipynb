{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PTA Data Analysis with enterprise</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will walk you through the basics of running a gravitational wave search on pulsar timing array data using enterprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import glob, os, json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import enterprise\n",
    "from enterprise.pulsar import Pulsar\n",
    "import enterprise.signals.parameter as parameter\n",
    "from enterprise.signals import utils\n",
    "from enterprise.signals import signal_base\n",
    "from enterprise.signals import selections\n",
    "from enterprise.signals.selections import Selection\n",
    "from enterprise.signals import white_signals\n",
    "from enterprise.signals import gp_signals\n",
    "from enterprise.signals import deterministic_signals\n",
    "\n",
    "import corner\n",
    "from PTMCMCSampler.PTMCMCSampler import PTSampler as ptmcmc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load the data. Pulsar timing data is stored as par files, which contain a list of the pulsar's parameters and their uncertainties, and tim files, which contain the pulse times of arrival. Here we initialize all of the pulsar objects from the par and tim files (this will take a while).\n",
    "\n",
    "In this tutorial, we will only analyze a single pulsar, J1713+0747."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/home/sarah.vigeland/nanograv_data/11yr/partim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parfiles = sorted(glob.glob(datadir + 'J1713*.par'))\n",
    "timfiles = sorted(glob.glob(datadir + 'J1713*.tim'))\n",
    "\n",
    "psrs = []\n",
    "for p, t in zip(parfiles, timfiles):\n",
    "    psrname = parfiles[0].split('/')[-1].split('_')[0]\n",
    "    print 'Loading {0}'.format(psrname)\n",
    "    psr = Pulsar(p, t, ephem='DE436', clk='BIPM2015')\n",
    "    psrs.append(psr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's plot the residuals for this pulsar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(psrs[0].toas, psrs[0].residuals, ls='', marker='.', yerr=psrs[0].toaerrs)\n",
    "plt.ylabel('Residuals');\n",
    "plt.xlabel('MJD');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's add the white noise. There are three terms describing white noise: EFAC, which is a linear scaling of the TOA uncertainties; EQUAD, which is white noise added in quadrature to the TOA uncertainties; and ECORR, which is correlated over a single observation but uncorrelated between different observations.\n",
    "\n",
    "In our analysis, we will fix the white noise to the maximum-likelihood values, which are found from noise analyses run on each pulsar. For now we will initialize the white noise parameters as constants. Later, we will read in the white noise values from a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white noise parameters\n",
    "# here we define them as constants, later we will input the values after the model is initialized\n",
    "efac = parameter.Constant()\n",
    "equad = parameter.Constant()\n",
    "ecorr = parameter.Constant()\n",
    "\n",
    "# there will be separate white noise parameters for each observing backend\n",
    "# since NANOGrav began taking data, there have been two generations of backends\n",
    "# (ASP and PUPPI at Arecibo, GASP and GUPPI at Green Bank)\n",
    "selection = selections.Selection(selections.by_backend)\n",
    "\n",
    "# white noise signals\n",
    "ef = white_signals.MeasurementNoise(efac=efac, selection=selection)\n",
    "eq = white_signals.EquadNoise(log10_equad=equad, selection=selection)\n",
    "ec = gp_signals.EcorrBasisModel(log10_ecorr=ecorr, selection=selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add in the red noise. We model the red noise as a power law with two parameters: an amplitude and spectral index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red noise parameters\n",
    "log10_A = parameter.Uniform(-18, -11)\n",
    "gamma = parameter.Uniform(0, 7)\n",
    "\n",
    "# define powerlaw PSD and red noise signal\n",
    "pl = utils.powerlaw(log10_A=log10_A, gamma=gamma)\n",
    "rn = gp_signals.FourierBasisGP(pl, components=30, name='rn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also include contributions from the pulsar's timing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linearized timing model\n",
    "tm = gp_signals.TimingModel(use_svd=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define the GW background. We model the background as a power law with fixed spectral index and an amplitude parameter. You can also do runs where you vary the spectral index and the amplitude simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GW parameters (initialize with names here to use parameters in common across pulsars)\n",
    "log10_Agw = parameter.LinearExp(-18,-12)('log10_A_gw')\n",
    "gamma_gw = parameter.Constant(4.33)('gamma_gw')\n",
    "\n",
    "# gwb (no spatial correlations)\n",
    "cpl = utils.powerlaw(log10_A=log10_Agw, gamma=gamma_gw)\n",
    "gwb = gp_signals.FourierBasisGP(spectrum=cpl, components=30, name='gwb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put together all of the signals to define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full signal\n",
    "s = ef + eq + ec + rn + tm + gwb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only analzying a single pulsar, we will not include ephemeris modeling into the model. If you want to include it, set `bayesephem = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to include ephemeris modeling, set bayesephem = True\n",
    "bayesephem = False\n",
    "if bayesephem:\n",
    "    s += deterministic_signals.PhysicalEphemerisSignal(use_epoch_toas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initalize the PTA object, and fix the pulsars' white noise parameters to their maximum-likelihood values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize PTA\n",
    "model = [s(psr) for psr in psrs]\n",
    "pta = signal_base.PTA(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the pulsars' white noise parameters from their noise files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_from_pal2(noisefile):\n",
    "    psrname = noisefile.split('/')[-1].split('_noise.txt')[0]\n",
    "    fin = open(noisefile, 'r')\n",
    "    lines = fin.readlines()\n",
    "    params = {}\n",
    "    for line in lines:\n",
    "        ln = line.split()\n",
    "        if 'efac' in line:\n",
    "            par = 'efac'\n",
    "            flag = ln[0].split('efac-')[-1]\n",
    "        elif 'equad' in line:\n",
    "            par = 'log10_equad'\n",
    "            flag = ln[0].split('equad-')[-1]\n",
    "        elif 'jitter_q' in line:\n",
    "            par = 'log10_ecorr'\n",
    "            flag = ln[0].split('jitter_q-')[-1]\n",
    "#            flag = 'ecorr_{0}'.format(ln[0].split('jitter_q-')[-1])\n",
    "        elif 'RN-Amplitude' in line:\n",
    "            par = 'log10_A'\n",
    "            flag = ''\n",
    "        elif 'RN-spectral-index' in line:\n",
    "            par = 'gamma'\n",
    "            flag = ''\n",
    "        else:\n",
    "            break\n",
    "        if flag:\n",
    "            name = [psrname, flag, par]\n",
    "        else:\n",
    "            name = [psrname, par]\n",
    "        pname = '_'.join(name)\n",
    "        params.update({pname: float(ln[1])})\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisedir = '/home/sarah.vigeland/nanograv_data/11yr/noisefiles/'\n",
    "noisefiles = glob.glob(noisedir + '*_noise.txt')\n",
    "\n",
    "setpars = {}\n",
    "for nf in noisefiles:\n",
    "    setpars.update(get_noise_from_pal2(nf))\n",
    "\n",
    "pta.set_default_params(setpars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we draw the initial values for the parameters.\n",
    "\n",
    "This model only contains three parameters since we are only analyzing one pulsar, and we are not including `BayesEphem`. In general, if you run a gravitational wave search with fixed spectral index and without `BayesEphem`, you will have 2N + 1 parameters, where N is the number of pulsars in the PTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "ndim = len(x0)\n",
    "\n",
    "print ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pta.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set up a few other things before running the sampler. The sampler uses Adaptive Metropolis sampling, which uses the covariance matrix to determine the step sizes for the parameters. We initialize the covariance matrix as a diagonal matrix with the same value in each diagonal element. As the code runs, the covariance matrix will be updated based on the samples in the chain.\n",
    "\n",
    "We also need to set up parameter groups, which determine which parameters should be jumped in simultaneously. For this run, we only have three groups: one containing all of the parameters, one containing both of the red noise parameters, and one containing the GWB amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial jump covariance matrix\n",
    "cov = np.diag(np.ones(ndim) * 0.01**2)\n",
    "\n",
    "# set up jump groups by red noise groups \n",
    "ndim = len(x0)\n",
    "groups  = [range(0, ndim)]\n",
    "groups.extend(map(list, zip(range(0,ndim,2), range(1,ndim,2))))\n",
    "groups.extend([[ndim-1]])\n",
    "print groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = 'chains/'\n",
    "\n",
    "sampler = ptmcmc(ndim, pta.get_lnlikelihood, pta.get_lnprior, cov, groups=groups, \n",
    "                 outDir='chains/', resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler for N steps\n",
    "N = int(1e6)\n",
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "sampler.sample(x0, N, SCAMweight=30, AMweight=15, DEweight=50, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
